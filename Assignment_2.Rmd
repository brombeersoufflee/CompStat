```{r}
library("ggplot2")
library("tibble")
library("bootstrap")
library("magrittr")
library("dplyr")
library("partitions")

data(law)
law_red <- law
n = dim(law_red)[1]

law %<>% add_column(observation = 1:nrow(law), .before = 1)

ggplot(law, aes(x = LSAT, y = GPA)) +
geom_text(aes(label = observation),
hjust = 0, vjust = 0)



```

# Gray code function

# get the grey codes

```{r}

# get the number of all possible compositions 
allCompositions <- compositions(n,n)
total <- dim(allCompositions)[2]

# prepare a matrix that will store all possible subsets 
arr_com <- matrix(0, nrow = total, ncol = n)

get_grayCodes <- function(n, k){
  i<-1
  r <- array(0, n)
  r[i] <- n
  t <- n
  h <- 0
  arr_com[i, ] <- r
  i <- i + 1

  while(r[k]!=n){
    if (t!=1){
      h<-0
    }
    h <- h + 1
    t <- r[h]
    r[h] <- 0
    r[1] <- t - 1
    r[h+1] <- r[h+1] + 1
    arr_com[i, ] <- r
    i <- i + 1
  }
  return (arr_com)
}

# get the gray codes 
gray_codes <- get_grayCodes(n,n)

```

Run complete enumeration - due to the fact that there are over 7 million different bootstrap subsets, here we are just running partial enumeration, with 250k possible subsets.

```{r}

#calculating the raw pearson correlation coefficient
df_boot <- tibble(LSAT = numeric(), GPA = numeric() )
df_pearboot <- tibble(corr = numeric())
pearcorrraw <- cor(law$LSAT, law$GPA, method = "pearson")
pearboot <- numeric()

# sample row ids without replacment
fraction <- 250000
sample_ids <- sample(total, fraction, replace=FALSE)
sample_pointer <- 1

for (i in 1:fraction){
  
  # array for storing the bootstrap indicies
  ids <- array(0,0)
  n_points <- 0
  
  # random row from complete enumeration
  row_i <- sample_ids[sample_pointer]
  sample_pointer <- sample_pointer + 1
  for (j in 1:length(arr_com[row_i,])){
    # skip if there are no points 
    if (arr_com[row_i,j] == 0){
      next
    }
    
    # create a list of indicies for the subset 
    ids <- c(ids, array(j, arr_com[row_i,j]))
  }
  # calculate and append the correletion coefficient for a given subset 
  pearboot <- c(pearboot, cor(law_red[ids, ]$LSAT, law_red[ids, ]$GPA, method = "pearson"))
}

```

```{r}
hist(x = pearboot, breaks = 50, 
     main="correletion distribution with outliers",
     xlab = "Pearson Correlation Coefficient Estimate (red is true coefficient)")
abline(v = pearcorrraw, col = 'red')
```

Monte Carlo Simulation:

```{r}
n = length(law$GPA)
# normalise the columns
law %<>% add_column(norm_gpa=law$GPA/max(law$GPA))
law %<>% add_column(norm_lsat=law$LSAT/max(law$LSAT))

# add a column with the difference and take the absolute value
law %<>% add_column(diff=law$norm_gpa-law$norm_lsat)
abs_diff = abs(law$diff)

# generate random signs and assign these to the difference column
signs = matrix(replicate(bootcount*n, sample(c(-1,1), size =1)), nrow = bootcount) %>% as_tibble
names(signs) = paste0("x_", 1:n)
signs %<>% mutate(t = sapply(1:nrow(signs), function(i) sum(signs[i,]*abs_diff)))
t_obs = sum(law$diff)
pvalue = mean(abs(signs$t) >= abs(t_obs))
print(pvalue)
# with bootcount=40000 the pvalue is 0.898825

# plot the histogram with pvalue
ggplot(signs, aes(t)) + geom_histogram(binwidth = 0.03) + geom_vline(xintercept = c(-t_obs, t_obs), colour = "red", size = 1.5)

```
